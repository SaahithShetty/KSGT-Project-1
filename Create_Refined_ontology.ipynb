{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 completed: Core classes defined with clear relationships\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Graph, Namespace, Literal, RDF, RDFS, OWL, XSD\n",
    "\n",
    "# Create a new graph\n",
    "g = Graph()\n",
    "\n",
    "# Define namespaces\n",
    "HI = Namespace(\"http://www.semanticweb.org/hi_ontology#\")\n",
    "g.bind(\"hi\", HI)\n",
    "g.bind(\"owl\", OWL)\n",
    "g.bind(\"rdfs\", RDFS)\n",
    "\n",
    "# Define the main classes\n",
    "classes = [\n",
    "    \"Agent\",           # Base class for all actors\n",
    "    \"Human\",           # Human class\n",
    "    \"Human_Agent\",     # Human acting as an agent\n",
    "    \"AI_Agent\",        # AI system acting as an agent\n",
    "    \"Scenario\",        # Context of interaction\n",
    "    \"ResearchPaper\",   # Academic paper describing scenarios\n",
    "    \"Task\",            # Activities performed in scenarios\n",
    "    \"Evaluation\",      # Assessment methods\n",
    "    \"Score\"            # Results of evaluations\n",
    "]\n",
    "\n",
    "# Add classes to the ontology\n",
    "for cls in classes:\n",
    "    g.add((HI[cls], RDF.type, OWL.Class))\n",
    "    g.add((HI[cls], RDFS.label, Literal(cls)))\n",
    "\n",
    "# Define subclass relationships\n",
    "g.add((HI.Human_Agent, RDFS.subClassOf, HI.Agent))\n",
    "g.add((HI.Human_Agent, RDFS.subClassOf, HI.Human))\n",
    "g.add((HI.AI_Agent, RDFS.subClassOf, HI.Agent))\n",
    "\n",
    "# Add class descriptions to clarify distinctions\n",
    "g.add((HI.Human, RDFS.comment, Literal(\"General class representing human beings\")))\n",
    "g.add((HI.Human_Agent, RDFS.comment, Literal(\"A human specifically acting as an agent in human-AI interaction\")))\n",
    "g.add((HI.AI_Agent, RDFS.comment, Literal(\"An artificial intelligence system acting as an agent\")))\n",
    "\n",
    "# Save the ontology\n",
    "g.serialize(destination=\"new_hi_ontology.ttl\", format=\"turtle\")\n",
    "print(\"Step 1 completed: Core classes defined with clear relationships\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2 completed: Object and data properties defined to connect entities\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Graph, Namespace, Literal, RDF, RDFS, OWL, XSD\n",
    "\n",
    "# Load the ontology created in Step 1\n",
    "g = Graph()\n",
    "g.parse(\"new_hi_ontology.ttl\", format=\"turtle\")\n",
    "\n",
    "# Define namespace\n",
    "HI = Namespace(\"http://www.semanticweb.org/hi_ontology#\")\n",
    "g.bind(\"hi\", HI)\n",
    "\n",
    "# Define object properties to connect entities\n",
    "object_properties = {\n",
    "    \"describedIn\": (None, HI.ResearchPaper),  # Entity is described in a research paper\n",
    "    \"performsTask\": (HI.Agent, HI.Task),      # Agent performs a task\n",
    "    \"evaluatedWith\": (HI.Agent, HI.Evaluation), # Agent is evaluated with a method\n",
    "    \"achievesScore\": (HI.Agent, HI.Score),    # Agent achieves a score\n",
    "    \"appliesTo\": (HI.Evaluation, HI.Task),    # Evaluation applies to a task\n",
    "    \"partOf\": (HI.Task, HI.Scenario),         # Task is part of a scenario\n",
    "    \"interactsWith\": (HI.Human_Agent, HI.AI_Agent), # Human agent interacts with AI agent\n",
    "    \"basedOn\": (HI.Scenario, HI.ResearchPaper), # Scenario is based on a research paper\n",
    "    \"hasResult\": (HI.Evaluation, HI.Score)    # Evaluation has a score result\n",
    "}\n",
    "\n",
    "# Add object properties to the ontology\n",
    "for prop, (domain, range_) in object_properties.items():\n",
    "    g.add((HI[prop], RDF.type, OWL.ObjectProperty))\n",
    "    g.add((HI[prop], RDFS.label, Literal(prop)))\n",
    "    \n",
    "    # Add domain if specified (None means no restriction)\n",
    "    if domain is not None:\n",
    "        g.add((HI[prop], RDFS.domain, domain))\n",
    "    \n",
    "    # Add range\n",
    "    g.add((HI[prop], RDFS.range, range_))\n",
    "\n",
    "# Define data properties for attributes\n",
    "data_properties = {\n",
    "    \"hasTitle\": (HI.ResearchPaper, XSD.string),\n",
    "    \"hasAuthor\": (HI.ResearchPaper, XSD.string),\n",
    "    \"hasYear\": (HI.ResearchPaper, XSD.integer),\n",
    "    \"hasDOI\": (HI.ResearchPaper, XSD.string),\n",
    "    \"hasValue\": (HI.Score, XSD.float),\n",
    "    \"hasName\": (None, XSD.string),\n",
    "    \"hasDescription\": (None, XSD.string)\n",
    "}\n",
    "\n",
    "# Add data properties to the ontology\n",
    "for prop, (domain, range_) in data_properties.items():\n",
    "    g.add((HI[prop], RDF.type, OWL.DatatypeProperty))\n",
    "    g.add((HI[prop], RDFS.label, Literal(prop)))\n",
    "    \n",
    "    # Add domain if specified\n",
    "    if domain is not None:\n",
    "        g.add((HI[prop], RDFS.domain, domain))\n",
    "    \n",
    "    # Add range\n",
    "    g.add((HI[prop], RDFS.range, range_))\n",
    "\n",
    "# Save the updated ontology\n",
    "g.serialize(destination=\"new_hi_ontology.ttl\", format=\"turtle\")\n",
    "print(\"Step 2 completed: Object and data properties defined to connect entities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added concepts from the paper to the ontology with proper relationships\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Graph, Namespace, Literal, URIRef\n",
    "from rdflib.namespace import RDF, RDFS, OWL, XSD\n",
    "import uuid\n",
    "\n",
    "# Load the existing ontology\n",
    "g = Graph()\n",
    "g.parse(\"new_hi_ontology.ttl\", format=\"turtle\")\n",
    "\n",
    "# Define namespaces\n",
    "HI = Namespace(\"http://www.semanticweb.org/hi_ontology#\")\n",
    "g.bind(\"hi\", HI)\n",
    "\n",
    "# Define paper metadata\n",
    "paper_id = \"ConversationalAgentDiaryConstruction\"\n",
    "paper_uri = HI[paper_id]\n",
    "g.add((paper_uri, RDF.type, HI.ResearchPaper))\n",
    "g.add((paper_uri, HI.hasTitle, Literal(\"A Conversational Agent for Structured Diary Construction Enabling Monitoring of Functioning & Well-Being\")))\n",
    "g.add((paper_uri, HI.hasAuthor, Literal(\"Piek Vossen, Selene Báez Santamaría, Thomas Baier\")))\n",
    "g.add((paper_uri, HI.hasYear, Literal(2024, datatype=XSD.integer)))\n",
    "g.add((paper_uri, HI.hasDOI, Literal(\"10.3233/FAIA240204\")))\n",
    "g.add((paper_uri, HI.hasVenue, Literal(\"Frontiers in Artificial Intelligence and Applications\")))\n",
    "\n",
    "# Create scenario based on paper\n",
    "scenario_uri = HI[\"DiaryConstructionScenario\"]\n",
    "g.add((scenario_uri, RDF.type, HI.Scenario))\n",
    "g.add((scenario_uri, HI.hasName, Literal(\"Diary Construction Scenario\")))\n",
    "g.add((scenario_uri, HI.basedOn, paper_uri))\n",
    "g.add((scenario_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "# Add key concepts from the paper\n",
    "# 1. Define Hybrid Intelligence Agent\n",
    "agent_uri = HI[\"HybridIntelligenceAgent\"]\n",
    "g.add((agent_uri, RDF.type, HI.AI_Agent))\n",
    "g.add((agent_uri, HI.hasName, Literal(\"Hybrid Intelligence Conversational Agent\")))\n",
    "g.add((agent_uri, HI.hasDescription, Literal(\"An agent that constructs a personal diary through conversation\")))\n",
    "g.add((agent_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "# 2. Define Human User (Patient)\n",
    "human_uri = HI[\"DiaryUser\"]\n",
    "g.add((human_uri, RDF.type, HI.Human_Agent))\n",
    "g.add((human_uri, HI.hasName, Literal(\"Diary User/Patient\")))\n",
    "g.add((human_uri, HI.hasDescription, Literal(\"Person interacting with the conversational agent to build a diary\")))\n",
    "g.add((human_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "# 3. Define main tasks\n",
    "diary_construction_task = HI[\"DiaryConstructionTask\"]\n",
    "g.add((diary_construction_task, RDF.type, HI.Task))\n",
    "g.add((diary_construction_task, HI.hasName, Literal(\"Diary Construction\")))\n",
    "g.add((diary_construction_task, HI.hasDescription, Literal(\"Creating a structured diary through conversation\")))\n",
    "g.add((diary_construction_task, HI.partOf, scenario_uri))\n",
    "g.add((diary_construction_task, HI.describedIn, paper_uri))\n",
    "\n",
    "timeline_reconstruction_task = HI[\"TimelineReconstructionTask\"]\n",
    "g.add((timeline_reconstruction_task, RDF.type, HI.Task))\n",
    "g.add((timeline_reconstruction_task, HI.hasName, Literal(\"Timeline Reconstruction\")))\n",
    "g.add((timeline_reconstruction_task, HI.hasDescription, Literal(\"Reconstructing a timeline of events through conversation\")))\n",
    "g.add((timeline_reconstruction_task, HI.partOf, scenario_uri))\n",
    "g.add((timeline_reconstruction_task, HI.describedIn, paper_uri))\n",
    "\n",
    "monitoring_task = HI[\"WellBeingMonitoringTask\"]\n",
    "g.add((monitoring_task, RDF.type, HI.Task))\n",
    "g.add((monitoring_task, HI.hasName, Literal(\"Well-Being Monitoring\")))\n",
    "g.add((monitoring_task, HI.hasDescription, Literal(\"Monitoring physical, social and mental functioning through conversation\")))\n",
    "g.add((monitoring_task, HI.partOf, scenario_uri))\n",
    "g.add((monitoring_task, HI.describedIn, paper_uri))\n",
    "\n",
    "# 4. Connect actors to tasks\n",
    "g.add((agent_uri, HI.performsTask, diary_construction_task))\n",
    "g.add((agent_uri, HI.performsTask, timeline_reconstruction_task))\n",
    "g.add((agent_uri, HI.performsTask, monitoring_task))\n",
    "g.add((human_uri, HI.interactsWith, agent_uri))\n",
    "\n",
    "# 5. Knowledge representation components from the paper\n",
    "knowledge_graph_uri = HI[\"EpisodicKnowledgeGraph\"]\n",
    "g.add((knowledge_graph_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((knowledge_graph_uri, HI.hasName, Literal(\"Episodic Knowledge Graph\")))\n",
    "g.add((knowledge_graph_uri, HI.hasDescription, Literal(\"A timeline of events represented as a knowledge graph\")))\n",
    "g.add((knowledge_graph_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "event_model_uri = HI[\"SimpleEventModel\"]\n",
    "g.add((event_model_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((event_model_uri, HI.hasName, Literal(\"Simple Event Model\")))\n",
    "g.add((event_model_uri, HI.hasDescription, Literal(\"Formal model for defining events in someone's life\")))\n",
    "g.add((event_model_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "grasp_uri = HI[\"GRaSPFramework\"]\n",
    "g.add((grasp_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((grasp_uri, HI.hasName, Literal(\"GRaSP Framework\")))\n",
    "g.add((grasp_uri, HI.hasDescription, Literal(\"Framework to represent mentions of events in conversation\")))\n",
    "g.add((grasp_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "# 6. Connect components to the agent\n",
    "g.add((agent_uri, HI.uses, knowledge_graph_uri))\n",
    "g.add((agent_uri, HI.uses, event_model_uri))\n",
    "g.add((agent_uri, HI.uses, grasp_uri))\n",
    "\n",
    "# 7. Add medical use cases\n",
    "patient_recovery_uri = HI[\"PatientRecoveryUseCase\"]\n",
    "g.add((patient_recovery_uri, RDF.type, HI.Scenario))\n",
    "g.add((patient_recovery_uri, HI.hasName, Literal(\"Patient Recovery and Functioning Patterns\")))\n",
    "g.add((patient_recovery_uri, HI.hasDescription, Literal(\"Monitoring recovery and functioning of elderly patients\")))\n",
    "g.add((patient_recovery_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "diabetes_uri = HI[\"DiabetesUseCase\"]\n",
    "g.add((diabetes_uri, RDF.type, HI.Scenario))\n",
    "g.add((diabetes_uri, HI.hasName, Literal(\"Diabetes Management\")))\n",
    "g.add((diabetes_uri, HI.hasDescription, Literal(\"Supporting lifestyle changes for patients with Type 2 Diabetes Mellitus\")))\n",
    "g.add((diabetes_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "toxicity_uri = HI[\"ToxicityUseCase\"]\n",
    "g.add((toxicity_uri, RDF.type, HI.Scenario))\n",
    "g.add((toxicity_uri, HI.hasName, Literal(\"Cancer Therapy Toxicity Monitoring\")))\n",
    "g.add((toxicity_uri, HI.hasDescription, Literal(\"Monitoring side effects of cancer treatments like chemotherapy\")))\n",
    "g.add((toxicity_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "# 8. Connect use cases to the main scenario\n",
    "g.add((patient_recovery_uri, HI.relatedTo, scenario_uri))\n",
    "g.add((diabetes_uri, HI.relatedTo, scenario_uri))\n",
    "g.add((toxicity_uri, HI.relatedTo, scenario_uri))\n",
    "\n",
    "# 9. Add conversational intents from the paper\n",
    "high_level_intent_uri = HI[\"TimelineDrivenIntent\"]\n",
    "g.add((high_level_intent_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((high_level_intent_uri, HI.hasName, Literal(\"Timeline-Driven Intent\")))\n",
    "g.add((high_level_intent_uri, HI.hasDescription, Literal(\"High-level intents driven by the timeline, e.g., verifying expected events\")))\n",
    "g.add((high_level_intent_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "mid_level_intent_uri = HI[\"PropertyDrivenIntent\"]\n",
    "g.add((mid_level_intent_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((mid_level_intent_uri, HI.hasName, Literal(\"Property-Driven Intent\")))\n",
    "g.add((mid_level_intent_uri, HI.hasDescription, Literal(\"Mid-level intents driven by necessary/possible/probable properties in the ontology\")))\n",
    "g.add((mid_level_intent_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "low_level_intent_uri = HI[\"PerspectiveDrivenIntent\"]\n",
    "g.add((low_level_intent_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((low_level_intent_uri, HI.hasName, Literal(\"Perspective-Driven Intent\")))\n",
    "g.add((low_level_intent_uri, HI.hasDescription, Literal(\"Low-level intents driven by possible and likely perspectives\")))\n",
    "g.add((low_level_intent_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "# 10. Connect intents to the agent\n",
    "g.add((agent_uri, HI.uses, high_level_intent_uri))\n",
    "g.add((agent_uri, HI.uses, mid_level_intent_uri))\n",
    "g.add((agent_uri, HI.uses, low_level_intent_uri))\n",
    "\n",
    "# Save the updated ontology\n",
    "g.serialize(destination=\"new_hi_ontology.ttl\", format=\"turtle\")\n",
    "print(\"Successfully added concepts from the paper to the ontology with proper relationships\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added Exosoul ethical profiling concepts to the ontology with proper relationships\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Graph, Namespace, Literal, URIRef\n",
    "from rdflib.namespace import RDF, RDFS, OWL, XSD\n",
    "\n",
    "# Load the existing ontology\n",
    "g = Graph()\n",
    "g.parse(\"new_hi_ontology.ttl\", format=\"turtle\")\n",
    "\n",
    "# Define namespaces\n",
    "HI = Namespace(\"http://www.semanticweb.org/hi_ontology#\")\n",
    "g.bind(\"hi\", HI)\n",
    "\n",
    "# Add the Exosoul paper to the ontology\n",
    "paper_id = \"ExosoulEthicalProfiling\"\n",
    "paper_uri = HI[paper_id]\n",
    "g.add((paper_uri, RDF.type, HI.ResearchPaper))\n",
    "g.add((paper_uri, HI.hasTitle, Literal(\"Exosoul: Ethical Profiling in the Digital World\")))\n",
    "g.add((paper_uri, HI.hasAuthor, Literal(\"Costanza Alfieri, Paola Inverardi, Patrizio Migliarini, Massimiliano Palmiero\")))\n",
    "g.add((paper_uri, HI.hasYear, Literal(2022, datatype=XSD.integer)))\n",
    "g.add((paper_uri, HI.hasDOI, Literal(\"10.3233/FAIA220194\")))\n",
    "g.add((paper_uri, HI.hasVenue, Literal(\"HHAI2022: Augmenting Human Intellect\")))\n",
    "\n",
    "# Create scenario based on paper\n",
    "scenario_uri = HI[\"EthicalProfilingScenario\"]\n",
    "g.add((scenario_uri, RDF.type, HI.Scenario))\n",
    "g.add((scenario_uri, HI.hasName, Literal(\"Ethical Profiling Scenario\")))\n",
    "g.add((scenario_uri, HI.hasDescription, Literal(\"A scenario for creating ethical profiles of users to predict digital behaviors\")))\n",
    "g.add((scenario_uri, HI.basedOn, paper_uri))\n",
    "g.add((scenario_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "# Add Ethics Position Theory concepts\n",
    "ept_uri = HI[\"EthicsPositionTheory\"]\n",
    "g.add((ept_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((ept_uri, HI.hasName, Literal(\"Ethics Position Theory\")))\n",
    "g.add((ept_uri, HI.hasDescription, Literal(\"Theory suggesting individuals' differences in moral judgments based on idealism and relativism\")))\n",
    "g.add((ept_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "idealism_uri = HI[\"Idealism\"]\n",
    "g.add((idealism_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((idealism_uri, HI.hasName, Literal(\"Idealism\")))\n",
    "g.add((idealism_uri, HI.hasDescription, Literal(\"Reflects absolute moral principles, oriented to truth, benevolence and avoiding harming others\")))\n",
    "g.add((idealism_uri, HI.partOf, ept_uri))\n",
    "g.add((idealism_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "relativism_uri = HI[\"Relativism\"]\n",
    "g.add((relativism_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((relativism_uri, HI.hasName, Literal(\"Relativism\")))\n",
    "g.add((relativism_uri, HI.hasDescription, Literal(\"Relies on evaluations of situations, contexts and consequences, reflecting that harm may be necessary for good\")))\n",
    "g.add((relativism_uri, HI.partOf, ept_uri))\n",
    "g.add((relativism_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "# Add moral philosophy types from EPT\n",
    "absolutist_uri = HI[\"Absolutist\"]\n",
    "g.add((absolutist_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((absolutist_uri, HI.hasName, Literal(\"Absolutist\")))\n",
    "g.add((absolutist_uri, HI.hasDescription, Literal(\"Principled idealists who endorse both reliance on moral standards and striving to minimize harm\")))\n",
    "g.add((absolutist_uri, HI.partOf, ept_uri))\n",
    "g.add((absolutist_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "situationist_uri = HI[\"Situationist\"]\n",
    "g.add((situationist_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((situationist_uri, HI.hasName, Literal(\"Situationist\")))\n",
    "g.add((situationist_uri, HI.hasDescription, Literal(\"Idealistic contextualists who value minimizing harm rather than reliance on moral standards\")))\n",
    "g.add((situationist_uri, HI.partOf, ept_uri))\n",
    "g.add((situationist_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "subjectivist_uri = HI[\"Subjectivist\"]\n",
    "g.add((subjectivist_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((subjectivist_uri, HI.hasName, Literal(\"Subjectivist\")))\n",
    "g.add((subjectivist_uri, HI.hasDescription, Literal(\"Realists who do not endorse moral standards or the avoidance of harmful consequences\")))\n",
    "g.add((subjectivist_uri, HI.partOf, ept_uri))\n",
    "g.add((subjectivist_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "exceptionist_uri = HI[\"Exceptionist\"]\n",
    "g.add((exceptionist_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((exceptionist_uri, HI.hasName, Literal(\"Exceptionist\")))\n",
    "g.add((exceptionist_uri, HI.hasDescription, Literal(\"Conventionalists who tolerate exceptions to moral standards when benefits offset potential harmful consequences\")))\n",
    "g.add((exceptionist_uri, HI.partOf, ept_uri))\n",
    "g.add((exceptionist_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "# Add personality traits related to ethics\n",
    "honesty_humility_uri = HI[\"HonestyHumility\"]\n",
    "g.add((honesty_humility_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((honesty_humility_uri, HI.hasName, Literal(\"Honesty/Humility\")))\n",
    "g.add((honesty_humility_uri, HI.hasDescription, Literal(\"Personality trait reflecting sincerity, fairness, modesty, and lack of manipulation\")))\n",
    "g.add((honesty_humility_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "conscientiousness_uri = HI[\"Conscientiousness\"]\n",
    "g.add((conscientiousness_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((conscientiousness_uri, HI.hasName, Literal(\"Conscientiousness\")))\n",
    "g.add((conscientiousness_uri, HI.hasDescription, Literal(\"Personality trait reflecting persistence, orderliness, self-regulation and integrity\")))\n",
    "g.add((conscientiousness_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "machiavellianism_uri = HI[\"Machiavellianism\"]\n",
    "g.add((machiavellianism_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((machiavellianism_uri, HI.hasName, Literal(\"Machiavellianism\")))\n",
    "g.add((machiavellianism_uri, HI.hasDescription, Literal(\"Personality trait reflecting manipulative tactics, cynicism, and 'the ends justify the means' attitude\")))\n",
    "g.add((machiavellianism_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "narcissism_uri = HI[\"Narcissism\"]\n",
    "g.add((narcissism_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((narcissism_uri, HI.hasName, Literal(\"Narcissism\")))\n",
    "g.add((narcissism_uri, HI.hasDescription, Literal(\"Personality trait reflecting inflated opinion of self, entitlement, superiority and need for admiration\")))\n",
    "g.add((narcissism_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "# Add digital behavior types\n",
    "privacy_violation_uri = HI[\"PrivacyViolation\"]\n",
    "g.add((privacy_violation_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((privacy_violation_uri, HI.hasName, Literal(\"Privacy Violation\")))\n",
    "g.add((privacy_violation_uri, HI.hasDescription, Literal(\"Using others' personal information without permission\")))\n",
    "g.add((privacy_violation_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "copyright_infringement_uri = HI[\"CopyrightInfringement\"]\n",
    "g.add((copyright_infringement_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((copyright_infringement_uri, HI.hasName, Literal(\"Copyright Infringement\")))\n",
    "g.add((copyright_infringement_uri, HI.hasDescription, Literal(\"Using software or content without owning a license\")))\n",
    "g.add((copyright_infringement_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "caution_uri = HI[\"Caution\"]\n",
    "g.add((caution_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((caution_uri, HI.hasName, Literal(\"Caution\")))\n",
    "g.add((caution_uri, HI.hasDescription, Literal(\"Reading privacy policies and being cautious with personal information online\")))\n",
    "g.add((caution_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "# Add ethical profile types from the clustering\n",
    "virtuous_profile_uri = HI[\"VirtuousProfile\"]\n",
    "g.add((virtuous_profile_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((virtuous_profile_uri, HI.hasName, Literal(\"Virtuous Profile\")))\n",
    "g.add((virtuous_profile_uri, HI.hasDescription, Literal(\"Ethical profile with high idealism, honesty/humility, conscientiousness and low relativism, Machiavellianism and narcissism\")))\n",
    "g.add((virtuous_profile_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "opportunist_profile_uri = HI[\"OpportunistProfile\"]\n",
    "g.add((opportunist_profile_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((opportunist_profile_uri, HI.hasName, Literal(\"Opportunist Profile\")))\n",
    "g.add((opportunist_profile_uri, HI.hasDescription, Literal(\"Ethical profile with low idealism, honesty/humility, conscientiousness and high relativism, Machiavellianism and narcissism\")))\n",
    "g.add((opportunist_profile_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "legalist_profile_uri = HI[\"LegalistProfile\"]\n",
    "g.add((legalist_profile_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((legalist_profile_uri, HI.hasName, Literal(\"Legalist Profile\")))\n",
    "g.add((legalist_profile_uri, HI.hasDescription, Literal(\"Ethical profile with moderate idealism and relativism, and high normativism\")))\n",
    "g.add((legalist_profile_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "sensible_profile_uri = HI[\"SensibleProfile\"]\n",
    "g.add((sensible_profile_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((sensible_profile_uri, HI.hasName, Literal(\"Sensible Profile\")))\n",
    "g.add((sensible_profile_uri, HI.hasDescription, Literal(\"Ethical profile with moderate idealism, low relativism, and high honesty/humility\")))\n",
    "g.add((sensible_profile_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "# Add Exosoul project concepts\n",
    "exosoul_uri = HI[\"ExosoulProject\"]\n",
    "g.add((exosoul_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((exosoul_uri, HI.hasName, Literal(\"Exosoul Project\")))\n",
    "g.add((exosoul_uri, HI.hasDescription, Literal(\"Project aiming to develop a personalized software exoskeleton to protect and support citizen's ethics and privacy\")))\n",
    "g.add((exosoul_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "exoskeleton_uri = HI[\"SoftwareExoskeleton\"]\n",
    "g.add((exoskeleton_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((exoskeleton_uri, HI.hasName, Literal(\"Software Exoskeleton\")))\n",
    "g.add((exoskeleton_uri, HI.hasDescription, Literal(\"Software shield that protects users and mediates actions according to moral preferences\")))\n",
    "g.add((exoskeleton_uri, HI.partOf, exosoul_uri))\n",
    "g.add((exoskeleton_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "# Define relationships between concepts\n",
    "g.add((virtuous_profile_uri, HI.influences, caution_uri))\n",
    "g.add((virtuous_profile_uri, HI.prevents, privacy_violation_uri))\n",
    "g.add((virtuous_profile_uri, HI.prevents, copyright_infringement_uri))\n",
    "\n",
    "g.add((opportunist_profile_uri, HI.influences, privacy_violation_uri))\n",
    "g.add((opportunist_profile_uri, HI.influences, copyright_infringement_uri))\n",
    "g.add((opportunist_profile_uri, HI.prevents, caution_uri))\n",
    "\n",
    "g.add((idealism_uri, HI.positivelyCorrelatedWith, honesty_humility_uri))\n",
    "g.add((relativism_uri, HI.negativelyCorrelatedWith, honesty_humility_uri))\n",
    "g.add((machiavellianism_uri, HI.negativelyCorrelatedWith, idealism_uri))\n",
    "g.add((machiavellianism_uri, HI.positivelyCorrelatedWith, relativism_uri))\n",
    "\n",
    "g.add((exoskeleton_uri, HI.uses, virtuous_profile_uri))\n",
    "g.add((exoskeleton_uri, HI.uses, opportunist_profile_uri))\n",
    "g.add((exoskeleton_uri, HI.uses, legalist_profile_uri))\n",
    "g.add((exoskeleton_uri, HI.uses, sensible_profile_uri))\n",
    "\n",
    "# Add relevant tasks\n",
    "ethical_profiling_task = HI[\"EthicalProfilingTask\"]\n",
    "g.add((ethical_profiling_task, RDF.type, HI.Task))\n",
    "g.add((ethical_profiling_task, HI.hasName, Literal(\"Ethical Profiling\")))\n",
    "g.add((ethical_profiling_task, HI.hasDescription, Literal(\"Creating ethical profiles to predict digital behaviors\")))\n",
    "g.add((ethical_profiling_task, HI.partOf, scenario_uri))\n",
    "g.add((ethical_profiling_task, HI.describedIn, paper_uri))\n",
    "\n",
    "behavior_prediction_task = HI[\"BehaviorPredictionTask\"]\n",
    "g.add((behavior_prediction_task, RDF.type, HI.Task))\n",
    "g.add((behavior_prediction_task, HI.hasName, Literal(\"Behavior Prediction\")))\n",
    "g.add((behavior_prediction_task, HI.hasDescription, Literal(\"Predicting digital behaviors based on ethical profiles\")))\n",
    "g.add((behavior_prediction_task, HI.partOf, scenario_uri))\n",
    "g.add((behavior_prediction_task, HI.describedIn, paper_uri))\n",
    "\n",
    "# Define object property if not already defined\n",
    "if (HI.influences, RDF.type, OWL.ObjectProperty) not in g:\n",
    "    g.add((HI.influences, RDF.type, OWL.ObjectProperty))\n",
    "    g.add((HI.influences, RDFS.label, Literal(\"influences\")))\n",
    "\n",
    "if (HI.prevents, RDF.type, OWL.ObjectProperty) not in g:\n",
    "    g.add((HI.prevents, RDF.type, OWL.ObjectProperty))\n",
    "    g.add((HI.prevents, RDFS.label, Literal(\"prevents\")))\n",
    "\n",
    "if (HI.partOf, RDF.type, OWL.ObjectProperty) not in g:\n",
    "    g.add((HI.partOf, RDF.type, OWL.ObjectProperty))\n",
    "    g.add((HI.partOf, RDFS.label, Literal(\"partOf\")))\n",
    "    \n",
    "if (HI.uses, RDF.type, OWL.ObjectProperty) not in g:\n",
    "    g.add((HI.uses, RDF.type, OWL.ObjectProperty))\n",
    "    g.add((HI.uses, RDFS.label, Literal(\"uses\")))\n",
    "\n",
    "if (HI.positivelyCorrelatedWith, RDF.type, OWL.ObjectProperty) not in g:\n",
    "    g.add((HI.positivelyCorrelatedWith, RDF.type, OWL.ObjectProperty))\n",
    "    g.add((HI.positivelyCorrelatedWith, RDFS.label, Literal(\"positivelyCorrelatedWith\")))\n",
    "    \n",
    "if (HI.negativelyCorrelatedWith, RDF.type, OWL.ObjectProperty) not in g:\n",
    "    g.add((HI.negativelyCorrelatedWith, RDF.type, OWL.ObjectProperty))\n",
    "    g.add((HI.negativelyCorrelatedWith, RDFS.label, Literal(\"negativelyCorrelatedWith\")))\n",
    "\n",
    "# Save the updated ontology\n",
    "g.serialize(destination=\"new_hi_ontology.ttl\", format=\"turtle\")\n",
    "print(\"Successfully added Exosoul ethical profiling concepts to the ontology with proper relationships\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added trust interventions concepts to the ontology with proper relationships\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Graph, Namespace, Literal, URIRef\n",
    "from rdflib.namespace import RDF, RDFS, OWL, XSD\n",
    "\n",
    "# Load the existing ontology\n",
    "g = Graph()\n",
    "g.parse(\"new_hi_ontology.ttl\", format=\"turtle\")\n",
    "\n",
    "# Define namespace\n",
    "HI = Namespace(\"http://www.semanticweb.org/hi_ontology#\")\n",
    "g.bind(\"hi\", HI)\n",
    "\n",
    "# Add the paper to the ontology\n",
    "paper_id = \"TrustInterventionsHumanAI\"\n",
    "paper_uri = HI[paper_id]\n",
    "g.add((paper_uri, RDF.type, HI.ResearchPaper))\n",
    "g.add((paper_uri, HI.hasTitle, Literal(\"Exploring the Dynamic Nature of Trust Using Interventions in a Human-AI Collaborative Task\")))\n",
    "g.add((paper_uri, HI.hasAuthor, Literal(\"Sachini Weerawardhana, Michael Akintunde, Luc Moreau\")))\n",
    "g.add((paper_uri, HI.hasYear, Literal(2024, datatype=XSD.integer)))\n",
    "g.add((paper_uri, HI.hasDOI, Literal(\"10.3233/FAIA240206\")))\n",
    "g.add((paper_uri, HI.hasVenue, Literal(\"HHAI 2024: Hybrid Human AI Systems for the Social Good\")))\n",
    "\n",
    "# Create scenario based on paper\n",
    "scenario_uri = HI[\"TrustInterventionsScenario\"]\n",
    "g.add((scenario_uri, RDF.type, HI.Scenario))\n",
    "g.add((scenario_uri, HI.hasName, Literal(\"Trust Interventions in Human-AI Collaboration\")))\n",
    "g.add((scenario_uri, HI.hasDescription, Literal(\"A scenario exploring interventions as trust indicators in human-AI collaborative tasks with misaligned goals\")))\n",
    "g.add((scenario_uri, HI.basedOn, paper_uri))\n",
    "g.add((scenario_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "# Add key concepts from the paper\n",
    "# 1. Goal Alignment/Misalignment\n",
    "goal_alignment_uri = HI[\"GoalAlignment\"]\n",
    "g.add((goal_alignment_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((goal_alignment_uri, HI.hasName, Literal(\"Goal Alignment\")))\n",
    "g.add((goal_alignment_uri, HI.hasDescription, Literal(\"The degree to which the human's goal matches the AI's programmed goal\")))\n",
    "g.add((goal_alignment_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "goal_misalignment_uri = HI[\"GoalMisalignment\"]\n",
    "g.add((goal_misalignment_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((goal_misalignment_uri, HI.hasName, Literal(\"Goal Misalignment\")))\n",
    "g.add((goal_misalignment_uri, HI.hasDescription, Literal(\"When an agent's behavior or decisions do not fully align with what the user wants to accomplish\")))\n",
    "g.add((goal_misalignment_uri, HI.describedIn, paper_uri))\n",
    "g.add((goal_misalignment_uri, HI.negativelyCorrelatedWith, HI.Trust))\n",
    "\n",
    "# 2. Intervention behavior\n",
    "intervention_uri = HI[\"Intervention\"]\n",
    "g.add((intervention_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((intervention_uri, HI.hasName, Literal(\"Intervention\")))\n",
    "g.add((intervention_uri, HI.hasDescription, Literal(\"A human-initiated action to alter the agent's behavior, rejecting its decision and suggesting an alternative\")))\n",
    "g.add((intervention_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "intervention_frequency_uri = HI[\"InterventionFrequency\"]\n",
    "g.add((intervention_frequency_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((intervention_frequency_uri, HI.hasName, Literal(\"Intervention Frequency\")))\n",
    "g.add((intervention_frequency_uri, HI.hasDescription, Literal(\"The rate at which humans intervene in an AI system's decisions, used as a behavioral measure of trust\")))\n",
    "g.add((intervention_frequency_uri, HI.partOf, intervention_uri))\n",
    "g.add((intervention_frequency_uri, HI.describedIn, paper_uri))\n",
    "g.add((intervention_frequency_uri, HI.negativelyCorrelatedWith, HI.Trust))\n",
    "\n",
    "# 3. Compliance behavior\n",
    "compliance_uri = HI[\"Compliance\"]\n",
    "g.add((compliance_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((compliance_uri, HI.hasName, Literal(\"Compliance\")))\n",
    "g.add((compliance_uri, HI.hasDescription, Literal(\"When the human accepts the agent's decisions, a behavioral demonstration of trust\")))\n",
    "g.add((compliance_uri, HI.describedIn, paper_uri))\n",
    "g.add((compliance_uri, HI.positivelyCorrelatedWith, HI.Trust))\n",
    "\n",
    "# 4. Agent capability\n",
    "agent_capability_uri = HI[\"AgentCapability\"]\n",
    "g.add((agent_capability_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((agent_capability_uri, HI.hasName, Literal(\"Agent Capability\")))\n",
    "g.add((agent_capability_uri, HI.hasDescription, Literal(\"The agent's ability to act as a decision aid, reflecting partial alignment between what the agent optimizes for and the user's goals\")))\n",
    "g.add((agent_capability_uri, HI.describedIn, paper_uri))\n",
    "g.add((agent_capability_uri, HI.influences, intervention_frequency_uri))\n",
    "g.add((agent_capability_uri, HI.influences, HI.Trust))\n",
    "\n",
    "# 5. Environmental uncertainty\n",
    "environment_uncertainty_uri = HI[\"EnvironmentUncertainty\"]\n",
    "g.add((environment_uncertainty_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((environment_uncertainty_uri, HI.hasName, Literal(\"Environment Uncertainty\")))\n",
    "g.add((environment_uncertainty_uri, HI.hasDescription, Literal(\"Non-determinism in the environment, where external events occur outside the control of the agent and human\")))\n",
    "g.add((environment_uncertainty_uri, HI.describedIn, paper_uri))\n",
    "g.add((environment_uncertainty_uri, HI.negativelyCorrelatedWith, HI.Trust))\n",
    "g.add((environment_uncertainty_uri, HI.influences, intervention_frequency_uri))\n",
    "\n",
    "# 6. Trust as dynamic process\n",
    "dynamic_trust_uri = HI[\"DynamicTrust\"]\n",
    "g.add((dynamic_trust_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((dynamic_trust_uri, HI.hasName, Literal(\"Dynamic Trust\")))\n",
    "g.add((dynamic_trust_uri, HI.hasDescription, Literal(\"Trust as a dynamic process that changes over time, not a static one-time measurement\")))\n",
    "g.add((dynamic_trust_uri, HI.describedIn, paper_uri))\n",
    "g.add((dynamic_trust_uri, HI.relatedTo, HI.Trust))\n",
    "\n",
    "# 7. Trust measurement methods\n",
    "behavioral_trust_measurement_uri = HI[\"BehavioralTrustMeasurement\"]\n",
    "g.add((behavioral_trust_measurement_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((behavioral_trust_measurement_uri, HI.hasName, Literal(\"Behavioral Trust Measurement\")))\n",
    "g.add((behavioral_trust_measurement_uri, HI.hasDescription, Literal(\"Using behavioral indicators like intervention frequency to measure trust in human-AI interactions\")))\n",
    "g.add((behavioral_trust_measurement_uri, HI.describedIn, paper_uri))\n",
    "g.add((behavioral_trust_measurement_uri, HI.uses, intervention_frequency_uri))\n",
    "\n",
    "# 8. Miscalibrated trust\n",
    "miscalibrated_trust_uri = HI[\"MiscalibratedTrust\"]\n",
    "g.add((miscalibrated_trust_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((miscalibrated_trust_uri, HI.hasName, Literal(\"Miscalibrated Trust\")))\n",
    "g.add((miscalibrated_trust_uri, HI.hasDescription, Literal(\"When trust level doesn't match the actual capabilities of the system, leading to misuse or disuse\")))\n",
    "g.add((miscalibrated_trust_uri, HI.describedIn, paper_uri))\n",
    "g.add((miscalibrated_trust_uri, HI.subClassOf, HI.Trust))\n",
    "\n",
    "# 9. Add Trust if not already defined\n",
    "trust_uri = HI[\"Trust\"]\n",
    "if (trust_uri, RDF.type, HI.AI_Concept) not in g:\n",
    "    g.add((trust_uri, RDF.type, HI.AI_Concept))\n",
    "    g.add((trust_uri, HI.hasName, Literal(\"Trust\")))\n",
    "    g.add((trust_uri, HI.hasDescription, Literal(\"The attitude that an agent will help achieve an individual's goals in a situation characterized by uncertainty and vulnerability\")))\n",
    "\n",
    "# Add relevant tasks from the paper\n",
    "navigation_task_uri = HI[\"NavigationTask\"]\n",
    "g.add((navigation_task_uri, RDF.type, HI.Task))\n",
    "g.add((navigation_task_uri, HI.hasName, Literal(\"Navigation Task\")))\n",
    "g.add((navigation_task_uri, HI.hasDescription, Literal(\"A route planning task where the human collaborates with an agent having partially aligned goals\")))\n",
    "g.add((navigation_task_uri, HI.partOf, scenario_uri))\n",
    "g.add((navigation_task_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "# Add Human-AI actors\n",
    "navigator_human_uri = HI[\"NavigatorHuman\"]\n",
    "g.add((navigator_human_uri, RDF.type, HI.Human_Agent))\n",
    "g.add((navigator_human_uri, HI.hasName, Literal(\"Navigator Human\")))\n",
    "g.add((navigator_human_uri, HI.hasDescription, Literal(\"Human using the AI navigation system and making intervention decisions\")))\n",
    "g.add((navigator_human_uri, HI.describedIn, paper_uri))\n",
    "g.add((navigator_human_uri, HI.performsTask, navigation_task_uri))\n",
    "\n",
    "navigation_ai_uri = HI[\"NavigationAI\"]\n",
    "g.add((navigation_ai_uri, RDF.type, HI.AI_Agent))\n",
    "g.add((navigation_ai_uri, HI.hasName, Literal(\"Navigation AI\")))\n",
    "g.add((navigation_ai_uri, HI.hasDescription, Literal(\"AI agent that optimizes for either distance or time in a route planning task\")))\n",
    "g.add((navigation_ai_uri, HI.describedIn, paper_uri))\n",
    "g.add((navigation_ai_uri, HI.performsTask, navigation_task_uri))\n",
    "g.add((navigation_ai_uri, HI.uses, agent_capability_uri))\n",
    "\n",
    "# Connect the actors\n",
    "g.add((navigator_human_uri, HI.interactsWith, navigation_ai_uri))\n",
    "g.add((navigator_human_uri, HI.performsTask, intervention_uri))\n",
    "\n",
    "# Create relationships between concepts\n",
    "g.add((goal_misalignment_uri, HI.influences, intervention_frequency_uri))\n",
    "g.add((goal_misalignment_uri, HI.oppositeOf, goal_alignment_uri))\n",
    "g.add((intervention_frequency_uri, HI.measuredIn, navigation_task_uri))\n",
    "g.add((environment_uncertainty_uri, HI.influences, miscalibrated_trust_uri))\n",
    "\n",
    "# Save the updated ontology\n",
    "g.serialize(destination=\"new_hi_ontology.ttl\", format=\"turtle\")\n",
    "print(\"Successfully added trust interventions concepts to the ontology with proper relationships\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added Human-Centered AI for Dementia Care concepts to the ontology with proper relationships\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Graph, Namespace, Literal, URIRef\n",
    "from rdflib.namespace import RDF, RDFS, OWL, XSD\n",
    "\n",
    "# Load the existing ontology\n",
    "g = Graph()\n",
    "g.parse(\"new_hi_ontology.ttl\", format=\"turtle\")\n",
    "\n",
    "# Define namespaces\n",
    "HI = Namespace(\"http://www.semanticweb.org/hi_ontology#\")\n",
    "g.bind(\"hi\", HI)\n",
    "\n",
    "# Add the paper to the ontology\n",
    "paper_id = \"HumanCenteredAIDementiaCare\"\n",
    "paper_uri = HI[paper_id]\n",
    "g.add((paper_uri, RDF.type, HI.ResearchPaper))\n",
    "g.add((paper_uri, HI.hasTitle, Literal(\"Human-Centered AI for Dementia Care: Using Reinforcement Learning for Personalized Interventions Support in Eating and Drinking Scenarios\")))\n",
    "g.add((paper_uri, HI.hasAuthor, Literal(\"Wen-Tseng Chang, Shihan Wang, Stephanie Kramer, Michel Oey, Somaya Ben Allouch\")))\n",
    "g.add((paper_uri, HI.hasYear, Literal(2024, datatype=XSD.integer)))\n",
    "g.add((paper_uri, HI.hasDOI, Literal(\"10.3233/FAIA240185\")))\n",
    "g.add((paper_uri, HI.hasVenue, Literal(\"HHAI 2024: Hybrid Human AI Systems for the Social Good\")))\n",
    "\n",
    "# Create main scenario based on paper\n",
    "scenario_uri = HI[\"DementiaCareScenario\"]\n",
    "g.add((scenario_uri, RDF.type, HI.Scenario))\n",
    "g.add((scenario_uri, HI.hasName, Literal(\"Dementia Care Eating and Drinking Scenario\")))\n",
    "g.add((scenario_uri, HI.hasDescription, Literal(\"A scenario for providing personalized interventions to support people with early-stage dementia in managing their eating and drinking routines\")))\n",
    "g.add((scenario_uri, HI.basedOn, paper_uri))\n",
    "g.add((scenario_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "# Add key concepts from the paper\n",
    "# 1. JITAI concept\n",
    "jitai_uri = HI[\"JITAI_Concept\"]\n",
    "g.add((jitai_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((jitai_uri, HI.hasName, Literal(\"Just-in-Time Adaptive Intervention\")))\n",
    "g.add((jitai_uri, HI.hasDescription, Literal(\"Design concept aiming at adapting to an individual's changing internal and contextual state to provide the right type and amount of support\")))\n",
    "g.add((jitai_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "# 2. Reinforcement Learning\n",
    "rl_uri = HI[\"ReinforcementLearningDementiaCare\"]\n",
    "g.add((rl_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((rl_uri, HI.hasName, Literal(\"Reinforcement Learning for Personalized Interventions\")))\n",
    "g.add((rl_uri, HI.hasDescription, Literal(\"Application of RL techniques to determine suitable mix of signals for individual users with early-stage dementia\")))\n",
    "g.add((rl_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "# 3. Contextual Multi-armed Bandit\n",
    "cmab_uri = HI[\"ContextualMultiArmedBandit\"]\n",
    "g.add((cmab_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((cmab_uri, HI.hasName, Literal(\"Contextual Multi-Armed Bandit\")))\n",
    "g.add((cmab_uri, HI.hasDescription, Literal(\"Formulation to address unknown preferences of people with dementia in mealtime interventions\")))\n",
    "g.add((cmab_uri, HI.partOf, rl_uri))\n",
    "g.add((cmab_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "# 4. Human Simulator\n",
    "simulator_uri = HI[\"HumanSimulator\"]\n",
    "g.add((simulator_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((simulator_uri, HI.hasName, Literal(\"Human Simulator\")))\n",
    "g.add((simulator_uri, HI.hasDescription, Literal(\"Simulation of behaviors and responses of users with dementia to test AI system effectiveness in a controlled environment\")))\n",
    "g.add((simulator_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "# 5. Escalation Scenario\n",
    "escalation_uri = HI[\"ThreeStageEscalationScenario\"]\n",
    "g.add((escalation_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((escalation_uri, HI.hasName, Literal(\"Three-Stage Escalated Eating Scenario\")))\n",
    "g.add((escalation_uri, HI.hasDescription, Literal(\"Approach with increasing intensity of signals to gently guide dementia patients through eating routines\")))\n",
    "g.add((escalation_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "# 6. Empathic AI\n",
    "empathic_ai_uri = HI[\"EmpathicAI\"]\n",
    "g.add((empathic_ai_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((empathic_ai_uri, HI.hasName, Literal(\"Empathic AI\")))\n",
    "g.add((empathic_ai_uri, HI.hasDescription, Literal(\"AI designed to be perceived as empathic by users with cognitive impairments, improving acceptability and usability\")))\n",
    "g.add((empathic_ai_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "# 7. Signal Combinations\n",
    "signals_uri = HI[\"SignalCombinations\"]\n",
    "g.add((signals_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((signals_uri, HI.hasName, Literal(\"Multimodal Signal Combinations\")))\n",
    "g.add((signals_uri, HI.hasDescription, Literal(\"Combinations of low to high intensity signals including scent, music, light, image, voice, and video to nudge users\")))\n",
    "g.add((signals_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "# Add tasks from the paper\n",
    "eating_reminder_task_uri = HI[\"EatingReminderTask\"]\n",
    "g.add((eating_reminder_task_uri, RDF.type, HI.Task))\n",
    "g.add((eating_reminder_task_uri, HI.hasName, Literal(\"Eating Reminder\")))\n",
    "g.add((eating_reminder_task_uri, HI.hasDescription, Literal(\"Task of reminding people with dementia to eat and drink at appropriate times\")))\n",
    "g.add((eating_reminder_task_uri, HI.partOf, scenario_uri))\n",
    "g.add((eating_reminder_task_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "rl_optimization_task_uri = HI[\"RLOptimizationTask\"]\n",
    "g.add((rl_optimization_task_uri, RDF.type, HI.Task))\n",
    "g.add((rl_optimization_task_uri, HI.hasName, Literal(\"RL Signal Optimization\")))\n",
    "g.add((rl_optimization_task_uri, HI.hasDescription, Literal(\"Optimizing signal combinations based on user behavior and preferences using reinforcement learning\")))\n",
    "g.add((rl_optimization_task_uri, HI.partOf, scenario_uri))\n",
    "g.add((rl_optimization_task_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "# Add human and AI agents\n",
    "pwd_human_uri = HI[\"PwDUser\"]\n",
    "g.add((pwd_human_uri, RDF.type, HI.Human_Agent))\n",
    "g.add((pwd_human_uri, HI.hasName, Literal(\"Person with Early-Stage Dementia\")))\n",
    "g.add((pwd_human_uri, HI.hasDescription, Literal(\"User with early-stage dementia who needs assistance with eating and drinking routines\")))\n",
    "g.add((pwd_human_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "who_takes_care_ai_uri = HI[\"WhoTakesCareAI\"]\n",
    "g.add((who_takes_care_ai_uri, RDF.type, HI.AI_Agent))\n",
    "g.add((who_takes_care_ai_uri, HI.hasName, Literal(\"Who Takes Care AI System\")))\n",
    "g.add((who_takes_care_ai_uri, HI.hasDescription, Literal(\"Personalized AI system that adapts to individual behaviors and provides suitable signals to nudge eating behavior\")))\n",
    "g.add((who_takes_care_ai_uri, HI.describedIn, paper_uri))\n",
    "g.add((who_takes_care_ai_uri, HI.uses, rl_uri))\n",
    "g.add((who_takes_care_ai_uri, HI.uses, jitai_uri))\n",
    "g.add((who_takes_care_ai_uri, HI.uses, cmab_uri))\n",
    "g.add((who_takes_care_ai_uri, HI.uses, empathic_ai_uri))\n",
    "g.add((who_takes_care_ai_uri, HI.uses, signals_uri))\n",
    "\n",
    "# Connect agents to tasks\n",
    "g.add((who_takes_care_ai_uri, HI.performsTask, eating_reminder_task_uri))\n",
    "g.add((who_takes_care_ai_uri, HI.performsTask, rl_optimization_task_uri))\n",
    "g.add((pwd_human_uri, HI.interactsWith, who_takes_care_ai_uri))\n",
    "\n",
    "# Add RL algorithms as AI concepts\n",
    "cts_uri = HI[\"ContextualThompsonSampling\"]\n",
    "g.add((cts_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((cts_uri, HI.hasName, Literal(\"Contextual Thompson Sampling\")))\n",
    "g.add((cts_uri, HI.hasDescription, Literal(\"Reinforcement learning algorithm that adapts to each meal's context to optimize interventions\")))\n",
    "g.add((cts_uri, HI.partOf, rl_uri))\n",
    "g.add((cts_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "linucb_uri = HI[\"LinearUpperConfidenceBound\"]\n",
    "g.add((linucb_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((linucb_uri, HI.hasName, Literal(\"Linear Upper Confidence Bound\")))\n",
    "g.add((linucb_uri, HI.hasDescription, Literal(\"Contextual reinforcement learning algorithm for decision-making under uncertainty\")))\n",
    "g.add((linucb_uri, HI.partOf, rl_uri))\n",
    "g.add((linucb_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "# Define evaluation concepts\n",
    "eval_uri = HI[\"DementiaCareSystemEvaluation\"]\n",
    "g.add((eval_uri, RDF.type, HI.Evaluation))\n",
    "g.add((eval_uri, HI.hasName, Literal(\"Dementia Care System Evaluation\")))\n",
    "g.add((eval_uri, HI.hasDescription, Literal(\"Evaluation of the AI system's effectiveness in adapting to diverse user preferences and behaviors\")))\n",
    "g.add((eval_uri, HI.appliesTo, eating_reminder_task_uri))\n",
    "g.add((eval_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "sim_score_uri = HI[\"SimulationScore\"]\n",
    "g.add((sim_score_uri, RDF.type, HI.Score))\n",
    "g.add((sim_score_uri, HI.hasName, Literal(\"Simulation Performance Score\")))\n",
    "g.add((sim_score_uri, HI.hasValue, Literal(0.91, datatype=XSD.float)))  # Using the deep epsilon-greedy score from paper\n",
    "g.add((eval_uri, HI.hasResult, sim_score_uri))\n",
    "g.add((who_takes_care_ai_uri, HI.evaluatedWith, eval_uri))\n",
    "g.add((who_takes_care_ai_uri, HI.achievesScore, sim_score_uri))\n",
    "\n",
    "# Save the updated ontology\n",
    "g.serialize(destination=\"new_hi_ontology.ttl\", format=\"turtle\")\n",
    "print(\"Successfully added Human-Centered AI for Dementia Care concepts to the ontology with proper relationships\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added Hybrid Intelligence Approach to Training Generative Design Assistants concepts to the ontology with proper relationships\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Graph, Namespace, Literal, URIRef\n",
    "from rdflib.namespace import RDF, RDFS, OWL, XSD\n",
    "\n",
    "# Load the existing ontology\n",
    "g = Graph()\n",
    "g.parse(\"new_hi_ontology.ttl\", format=\"turtle\")\n",
    "\n",
    "# Define namespaces\n",
    "HI = Namespace(\"http://www.semanticweb.org/hi_ontology#\")\n",
    "g.bind(\"hi\", HI)\n",
    "\n",
    "# Add the paper to the ontology\n",
    "paper_id = \"HybridIntelligenceGenerativeDesign\"\n",
    "paper_uri = HI[paper_id]\n",
    "g.add((paper_uri, RDF.type, HI.ResearchPaper))\n",
    "g.add((paper_uri, HI.hasTitle, Literal(\"A Hybrid Intelligence Approach to Training Generative Design Assistants: Partnership Between Human Experts and AI Enhanced Co-Creative Tools\")))\n",
    "g.add((paper_uri, HI.hasAuthor, Literal(\"Yaoli Mao, Janet Rafner, Yi Wang, Jacob Sherson\")))\n",
    "g.add((paper_uri, HI.hasYear, Literal(2023, datatype=XSD.integer)))\n",
    "g.add((paper_uri, HI.hasDOI, Literal(\"10.3233/FAIA230078\")))\n",
    "g.add((paper_uri, HI.hasVenue, Literal(\"HHAI 2023: Augmenting Human Intellect\")))\n",
    "\n",
    "# Create main scenario based on paper\n",
    "scenario_uri = HI[\"GenerativeDesignTrainingScenario\"]\n",
    "g.add((scenario_uri, RDF.type, HI.Scenario))\n",
    "g.add((scenario_uri, HI.hasName, Literal(\"Generative Design Training Scenario\")))\n",
    "g.add((scenario_uri, HI.hasDescription, Literal(\"A scenario for individual experts to train and personalize their generative design assistants on the fly\")))\n",
    "g.add((scenario_uri, HI.basedOn, paper_uri))\n",
    "g.add((scenario_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "# Add key concepts from the paper\n",
    "# 1. Hybrid Intelligence Technology Acceptance Model (HI-TAM)\n",
    "hitam_uri = HI[\"HI_TAM_Concept\"]\n",
    "g.add((hitam_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((hitam_uri, HI.hasName, Literal(\"Hybrid Intelligence Technology Acceptance Model\")))\n",
    "g.add((hitam_uri, HI.hasDescription, Literal(\"A model adapted from AI-TAM incorporating key aspects from HI including AI transparency and user control to support both virtual assistant training and general human-AI mutual learning\")))\n",
    "g.add((hitam_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "# 2. Programmable Common Language\n",
    "common_lang_uri = HI[\"ProgrammableCommonLanguage\"]\n",
    "g.add((common_lang_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((common_lang_uri, HI.hasName, Literal(\"Programmable Common Language\")))\n",
    "g.add((common_lang_uri, HI.hasDescription, Literal(\"A grammar-based method for constructing common language between humans and algorithms allowing for the explicitation of individual experts' design goals\")))\n",
    "g.add((common_lang_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "# 3. Continual Learning Loops\n",
    "learning_loops_uri = HI[\"ContinualLearningLoops\"]\n",
    "g.add((learning_loops_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((learning_loops_uri, HI.hasName, Literal(\"Continual Learning Loops\")))\n",
    "g.add((learning_loops_uri, HI.hasDescription, Literal(\"Human-centered design principles to seamlessly integrate AI training into the expert's task workflow\")))\n",
    "g.add((learning_loops_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "# 4. Hybrid Intelligence Narrative\n",
    "hi_narrative_uri = HI[\"HybridIntelligenceNarrative\"]\n",
    "g.add((hi_narrative_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((hi_narrative_uri, HI.hasName, Literal(\"Hybrid Intelligence Narrative\")))\n",
    "g.add((hi_narrative_uri, HI.hasDescription, Literal(\"A narrative designed to create a psychologically safe space for co-creation without the fear of job-replacement\")))\n",
    "g.add((hi_narrative_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "# 5. Perceived Partnership\n",
    "perceived_partnership_uri = HI[\"PerceivedPartnership\"]\n",
    "g.add((perceived_partnership_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((perceived_partnership_uri, HI.hasName, Literal(\"Perceived Partnership\")))\n",
    "g.add((perceived_partnership_uri, HI.hasDescription, Literal(\"User's subjective perception of the degree to which an AI is perceived as a collaborative partner in the interaction\")))\n",
    "g.add((perceived_partnership_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "# Add tasks from the paper\n",
    "design_training_task_uri = HI[\"GenerativeDesignTrainingTask\"]\n",
    "g.add((design_training_task_uri, RDF.type, HI.Task))\n",
    "g.add((design_training_task_uri, HI.hasName, Literal(\"Generative Design Training\")))\n",
    "g.add((design_training_task_uri, HI.hasDescription, Literal(\"Task of training a generative design assistant through expressing design goals and providing feedback on designs\")))\n",
    "g.add((design_training_task_uri, HI.partOf, scenario_uri))\n",
    "g.add((design_training_task_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "floor_plan_task_uri = HI[\"FloorPlanDesignTask\"]\n",
    "g.add((floor_plan_task_uri, RDF.type, HI.Task))\n",
    "g.add((floor_plan_task_uri, HI.hasName, Literal(\"Floor Plan Design\")))\n",
    "g.add((floor_plan_task_uri, HI.hasDescription, Literal(\"Creating floor plan layouts of office buildings through co-creation with a generative design assistant\")))\n",
    "g.add((floor_plan_task_uri, HI.partOf, scenario_uri))\n",
    "g.add((floor_plan_task_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "# Add human and AI agents\n",
    "architect_uri = HI[\"ArchitecturalExpert\"]\n",
    "g.add((architect_uri, RDF.type, HI.Human_Agent))\n",
    "g.add((architect_uri, HI.hasName, Literal(\"Architectural Expert\")))\n",
    "g.add((architect_uri, HI.hasDescription, Literal(\"Human expert in architectural design who trains and personalizes the generative design assistant\")))\n",
    "g.add((architect_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "gd_assistant_uri = HI[\"GenerativeDesignAssistant\"]\n",
    "g.add((gd_assistant_uri, RDF.type, HI.AI_Agent))\n",
    "g.add((gd_assistant_uri, HI.hasName, Literal(\"Generative Design Assistant\")))\n",
    "g.add((gd_assistant_uri, HI.hasDescription, Literal(\"AI system trained to assist human experts by generating design solutions based on their inputs and preferences\")))\n",
    "g.add((gd_assistant_uri, HI.describedIn, paper_uri))\n",
    "g.add((gd_assistant_uri, HI.uses, common_lang_uri))\n",
    "g.add((gd_assistant_uri, HI.uses, learning_loops_uri))\n",
    "\n",
    "# Connect agents to tasks and each other\n",
    "g.add((architect_uri, HI.performsTask, floor_plan_task_uri))\n",
    "g.add((architect_uri, HI.performsTask, design_training_task_uri))\n",
    "g.add((architect_uri, HI.interactsWith, gd_assistant_uri))\n",
    "g.add((gd_assistant_uri, HI.performsTask, floor_plan_task_uri))\n",
    "\n",
    "# Add TAM variables as AI concepts\n",
    "user_control_uri = HI[\"UserControl\"]\n",
    "g.add((user_control_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((user_control_uri, HI.hasName, Literal(\"User Control\")))\n",
    "g.add((user_control_uri, HI.hasDescription, Literal(\"The level of control and autonomy the user feels they have over the AI tool\")))\n",
    "g.add((user_control_uri, HI.describedIn, paper_uri))\n",
    "g.add((user_control_uri, HI.positivelyCorrelatedWith, perceived_partnership_uri))\n",
    "\n",
    "ai_output_transparency_uri = HI[\"AIOutputTransparency\"]\n",
    "g.add((ai_output_transparency_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((ai_output_transparency_uri, HI.hasName, Literal(\"AI Output Transparency\")))\n",
    "g.add((ai_output_transparency_uri, HI.hasDescription, Literal(\"The degree to which the output generated by an AI system is understandable and interpretable to the human user\")))\n",
    "g.add((ai_output_transparency_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "# Add evaluation concepts\n",
    "hitam_eval_uri = HI[\"HITAM_Evaluation\"]\n",
    "g.add((hitam_eval_uri, RDF.type, HI.Evaluation))\n",
    "g.add((hitam_eval_uri, HI.hasName, Literal(\"HI-TAM Evaluation\")))\n",
    "g.add((hitam_eval_uri, HI.hasDescription, Literal(\"Evaluation of human experts' willingness to build partnership with generative design assistants\")))\n",
    "g.add((hitam_eval_uri, HI.appliesTo, design_training_task_uri))\n",
    "g.add((hitam_eval_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "partnership_score_uri = HI[\"PartnershipScore\"]\n",
    "g.add((partnership_score_uri, RDF.type, HI.Score))\n",
    "g.add((partnership_score_uri, HI.hasName, Literal(\"Partnership Score\")))\n",
    "g.add((partnership_score_uri, HI.hasValue, Literal(0.75, datatype=XSD.float)))  # Approximated from paper findings\n",
    "g.add((hitam_eval_uri, HI.hasResult, partnership_score_uri))\n",
    "g.add((architect_uri, HI.evaluatedWith, hitam_eval_uri))\n",
    "g.add((architect_uri, HI.achievesScore, partnership_score_uri))\n",
    "\n",
    "# Save the updated ontology\n",
    "g.serialize(destination=\"new_hi_ontology.ttl\", format=\"turtle\")\n",
    "print(\"Successfully added Hybrid Intelligence Approach to Training Generative Design Assistants concepts to the ontology with proper relationships\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added Landmarks in Case-Based Reasoning concepts to the ontology with proper relationships\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Graph, Namespace, Literal, URIRef\n",
    "from rdflib.namespace import RDF, RDFS, OWL, XSD\n",
    "\n",
    "# Load the existing ontology\n",
    "g = Graph()\n",
    "g.parse(\"new_hi_ontology.ttl\", format=\"turtle\")\n",
    "\n",
    "# Define namespaces\n",
    "HI = Namespace(\"http://www.semanticweb.org/hi_ontology#\")\n",
    "g.bind(\"hi\", HI)\n",
    "\n",
    "# Add the paper to the ontology\n",
    "paper_id = \"LandmarksCaseBasedReasoning\"\n",
    "paper_uri = HI[paper_id]\n",
    "g.add((paper_uri, RDF.type, HI.ResearchPaper))\n",
    "g.add((paper_uri, HI.hasTitle, Literal(\"Landmarks in Case-Based Reasoning: From Theory to Data\")))\n",
    "g.add((paper_uri, HI.hasAuthor, Literal(\"Wijnand van Woerkom, Davide Grossi, Henry Prakken, Bart Verheij\")))\n",
    "g.add((paper_uri, HI.hasYear, Literal(2022, datatype=XSD.integer)))\n",
    "g.add((paper_uri, HI.hasDOI, Literal(\"10.3233/FAIA220200\")))\n",
    "g.add((paper_uri, HI.hasVenue, Literal(\"HHAI2022: Augmenting Human Intellect\")))\n",
    "\n",
    "# Create main scenario based on paper\n",
    "scenario_uri = HI[\"CaseBasedReasoningScenario\"]\n",
    "g.add((scenario_uri, RDF.type, HI.Scenario))\n",
    "g.add((scenario_uri, HI.hasName, Literal(\"Case-Based Reasoning Scenario\")))\n",
    "g.add((scenario_uri, HI.hasDescription, Literal(\"A scenario for analyzing how machine learning systems draw on training data using theory of precedential constraint\")))\n",
    "g.add((scenario_uri, HI.basedOn, paper_uri))\n",
    "g.add((scenario_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "# Add key concepts from the paper\n",
    "# 1. Theory of Precedential Constraint\n",
    "precedential_constraint_uri = HI[\"PrecedentialConstraint\"]\n",
    "g.add((precedential_constraint_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((precedential_constraint_uri, HI.hasName, Literal(\"Theory of Precedential Constraint\")))\n",
    "g.add((precedential_constraint_uri, HI.hasDescription, Literal(\"A formal framework developed to describe the a fortiori reasoning process underlying case law, analyzing how precedents constrain decisions in new cases\")))\n",
    "g.add((precedential_constraint_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "# 2. Landmark Cases\n",
    "landmark_cases_uri = HI[\"LandmarkCases\"]\n",
    "g.add((landmark_cases_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((landmark_cases_uri, HI.hasName, Literal(\"Landmark Cases\")))\n",
    "g.add((landmark_cases_uri, HI.hasDescription, Literal(\"Cases that are minimal with respect to the forcing relation, representing new legal ground and cases that set precedent\")))\n",
    "g.add((landmark_cases_uri, HI.describedIn, paper_uri))\n",
    "g.add((landmark_cases_uri, HI.relatedTo, precedential_constraint_uri))\n",
    "\n",
    "# 3. Forcing Relation\n",
    "forcing_relation_uri = HI[\"ForcingRelation\"]\n",
    "g.add((forcing_relation_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((forcing_relation_uri, HI.hasName, Literal(\"Forcing Relation\")))\n",
    "g.add((forcing_relation_uri, HI.hasDescription, Literal(\"Relation that models a fortiori reasoning: if a fact situation F has been decided for outcome s and we encounter a situation G that is at least as good for s, then G should also be decided for s\")))\n",
    "g.add((forcing_relation_uri, HI.describedIn, paper_uri))\n",
    "g.add((forcing_relation_uri, HI.partOf, precedential_constraint_uri))\n",
    "\n",
    "# 4. Case-Based Reasoning for Explainable AI\n",
    "cbr_xai_uri = HI[\"CaseBasedReasoningXAI\"]\n",
    "g.add((cbr_xai_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((cbr_xai_uri, HI.hasName, Literal(\"Case-Based Reasoning for Explainable AI\")))\n",
    "g.add((cbr_xai_uri, HI.hasDescription, Literal(\"The idea of providing explanation of AI decisions through analogy with relevant training examples, based on case-based reasoning principles\")))\n",
    "g.add((cbr_xai_uri, HI.describedIn, paper_uri))\n",
    "g.add((cbr_xai_uri, HI.uses, landmark_cases_uri))\n",
    "g.add((cbr_xai_uri, HI.uses, precedential_constraint_uri))\n",
    "\n",
    "# 5. Dimension Ordering\n",
    "dimension_ordering_uri = HI[\"DimensionOrdering\"]\n",
    "g.add((dimension_ordering_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((dimension_ordering_uri, HI.hasName, Literal(\"Dimension Ordering\")))\n",
    "g.add((dimension_ordering_uri, HI.hasDescription, Literal(\"A method to determine the orders for dimensions in case-based reasoning by using statistical trends like logistic regression coefficients\")))\n",
    "g.add((dimension_ordering_uri, HI.describedIn, paper_uri))\n",
    "g.add((dimension_ordering_uri, HI.partOf, precedential_constraint_uri))\n",
    "\n",
    "# Add tasks from the paper\n",
    "interpretability_task_uri = HI[\"AIInterpretabilityTask\"]\n",
    "g.add((interpretability_task_uri, RDF.type, HI.Task))\n",
    "g.add((interpretability_task_uri, HI.hasName, Literal(\"AI Interpretability\")))\n",
    "g.add((interpretability_task_uri, HI.hasDescription, Literal(\"The task of elucidating the decision making process of machine learning systems\")))\n",
    "g.add((interpretability_task_uri, HI.partOf, scenario_uri))\n",
    "g.add((interpretability_task_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "case_analysis_task_uri = HI[\"CaseAnalysisTask\"]\n",
    "g.add((case_analysis_task_uri, RDF.type, HI.Task))\n",
    "g.add((case_analysis_task_uri, HI.hasName, Literal(\"Case Analysis\")))\n",
    "g.add((case_analysis_task_uri, HI.hasDescription, Literal(\"The task of analyzing case data to identify landmark cases and determine consistency with precedence\")))\n",
    "g.add((case_analysis_task_uri, HI.partOf, scenario_uri))\n",
    "g.add((case_analysis_task_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "# Add human and AI agents\n",
    "researcher_uri = HI[\"CaseResearcher\"]\n",
    "g.add((researcher_uri, RDF.type, HI.Human_Agent))\n",
    "g.add((researcher_uri, HI.hasName, Literal(\"Case Researcher\")))\n",
    "g.add((researcher_uri, HI.hasDescription, Literal(\"Human researcher analyzing machine learning training data as legal cases through the lens of precedential constraint\")))\n",
    "g.add((researcher_uri, HI.describedIn, paper_uri))\n",
    "g.add((researcher_uri, HI.performsTask, case_analysis_task_uri))\n",
    "\n",
    "ai_system_uri = HI[\"CaseBasedReasoningSystem\"]\n",
    "g.add((ai_system_uri, RDF.type, HI.AI_Agent))\n",
    "g.add((ai_system_uri, HI.hasName, Literal(\"Case-Based Reasoning System\")))\n",
    "g.add((ai_system_uri, HI.hasDescription, Literal(\"AI system that provides explanations by analogy with training examples using case-based reasoning principles\")))\n",
    "g.add((ai_system_uri, HI.describedIn, paper_uri))\n",
    "g.add((ai_system_uri, HI.performsTask, interpretability_task_uri))\n",
    "g.add((ai_system_uri, HI.uses, precedential_constraint_uri))\n",
    "g.add((ai_system_uri, HI.uses, landmark_cases_uri))\n",
    "\n",
    "# Connect concepts to related concepts in other papers\n",
    "g.add((cbr_xai_uri, HI.relatedTo, HI.Trust))  # Relating to Trust concept\n",
    "g.add((cbr_xai_uri, HI.relatedTo, HI.UserControl))  # Relating to User Control concept\n",
    "\n",
    "# Add evaluation concepts\n",
    "consistency_eval_uri = HI[\"ConsistencyEvaluation\"] \n",
    "g.add((consistency_eval_uri, RDF.type, HI.Evaluation))\n",
    "g.add((consistency_eval_uri, HI.hasName, Literal(\"Consistency Evaluation\")))\n",
    "g.add((consistency_eval_uri, HI.hasDescription, Literal(\"Evaluation of the degree to which training data obeys the precedent set by other examples\")))\n",
    "g.add((consistency_eval_uri, HI.appliesTo, case_analysis_task_uri))\n",
    "g.add((consistency_eval_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "compas_score_uri = HI[\"COMPASConsistencyScore\"]\n",
    "g.add((compas_score_uri, RDF.type, HI.Score))\n",
    "g.add((compas_score_uri, HI.hasName, Literal(\"COMPAS Consistency Score\")))\n",
    "g.add((compas_score_uri, HI.hasValue, Literal(0.08, datatype=XSD.float)))  # 8% consistent from the paper\n",
    "g.add((consistency_eval_uri, HI.hasResult, compas_score_uri))\n",
    "g.add((researcher_uri, HI.evaluatedWith, consistency_eval_uri))\n",
    "g.add((researcher_uri, HI.achievesScore, compas_score_uri))\n",
    "\n",
    "# Save the updated ontology\n",
    "g.serialize(destination=\"new_hi_ontology.ttl\", format=\"turtle\")\n",
    "print(\"Successfully added Landmarks in Case-Based Reasoning concepts to the ontology with proper relationships\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added Landmarks in Case-Based Reasoning concepts to the ontology with proper relationships\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Graph, Namespace, Literal, URIRef\n",
    "from rdflib.namespace import RDF, RDFS, OWL, XSD\n",
    "\n",
    "# Load the existing ontology\n",
    "g = Graph()\n",
    "g.parse(\"new_hi_ontology.ttl\", format=\"turtle\")\n",
    "\n",
    "# Define namespaces\n",
    "HI = Namespace(\"http://www.semanticweb.org/hi_ontology#\")\n",
    "g.bind(\"hi\", HI)\n",
    "\n",
    "# Add the paper to the ontology\n",
    "paper_id = \"LandmarksCaseBasedReasoning\"\n",
    "paper_uri = HI[paper_id]\n",
    "g.add((paper_uri, RDF.type, HI.ResearchPaper))\n",
    "g.add((paper_uri, HI.hasTitle, Literal(\"Landmarks in Case-Based Reasoning: From Theory to Data\")))\n",
    "g.add((paper_uri, HI.hasAuthor, Literal(\"Wijnand van Woerkom, Davide Grossi, Henry Prakken, Bart Verheij\")))\n",
    "g.add((paper_uri, HI.hasYear, Literal(2022, datatype=XSD.integer)))\n",
    "g.add((paper_uri, HI.hasDOI, Literal(\"10.3233/FAIA220200\")))\n",
    "g.add((paper_uri, HI.hasVenue, Literal(\"HHAI2022: Augmenting Human Intellect\")))\n",
    "\n",
    "# Create main scenario based on paper\n",
    "scenario_uri = HI[\"CaseBasedReasoningScenario\"]\n",
    "g.add((scenario_uri, RDF.type, HI.Scenario))\n",
    "g.add((scenario_uri, HI.hasName, Literal(\"Case-Based Reasoning Scenario\")))\n",
    "g.add((scenario_uri, HI.hasDescription, Literal(\"A scenario for analyzing how machine learning systems draw on training data using theory of precedential constraint\")))\n",
    "g.add((scenario_uri, HI.basedOn, paper_uri))\n",
    "g.add((scenario_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "# Add key concepts from the paper\n",
    "# 1. Theory of Precedential Constraint\n",
    "precedential_constraint_uri = HI[\"PrecedentialConstraint\"]\n",
    "g.add((precedential_constraint_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((precedential_constraint_uri, HI.hasName, Literal(\"Theory of Precedential Constraint\")))\n",
    "g.add((precedential_constraint_uri, HI.hasDescription, Literal(\"A formal framework developed to describe the a fortiori reasoning process underlying case law, analyzing how precedents constrain decisions in new cases\")))\n",
    "g.add((precedential_constraint_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "# 2. Landmark Cases\n",
    "landmark_cases_uri = HI[\"LandmarkCases\"]\n",
    "g.add((landmark_cases_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((landmark_cases_uri, HI.hasName, Literal(\"Landmark Cases\")))\n",
    "g.add((landmark_cases_uri, HI.hasDescription, Literal(\"Cases that are minimal with respect to the forcing relation, representing new legal ground and cases that set precedent\")))\n",
    "g.add((landmark_cases_uri, HI.describedIn, paper_uri))\n",
    "g.add((landmark_cases_uri, HI.relatedTo, precedential_constraint_uri))\n",
    "\n",
    "# 3. Forcing Relation\n",
    "forcing_relation_uri = HI[\"ForcingRelation\"]\n",
    "g.add((forcing_relation_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((forcing_relation_uri, HI.hasName, Literal(\"Forcing Relation\")))\n",
    "g.add((forcing_relation_uri, HI.hasDescription, Literal(\"Relation that models a fortiori reasoning: if a fact situation F has been decided for outcome s and we encounter a situation G that is at least as good for s, then G should also be decided for s\")))\n",
    "g.add((forcing_relation_uri, HI.describedIn, paper_uri))\n",
    "g.add((forcing_relation_uri, HI.partOf, precedential_constraint_uri))\n",
    "\n",
    "# 4. Case-Based Reasoning for Explainable AI\n",
    "cbr_xai_uri = HI[\"CaseBasedReasoningXAI\"]\n",
    "g.add((cbr_xai_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((cbr_xai_uri, HI.hasName, Literal(\"Case-Based Reasoning for Explainable AI\")))\n",
    "g.add((cbr_xai_uri, HI.hasDescription, Literal(\"The idea of providing explanation of AI decisions through analogy with relevant training examples, based on case-based reasoning principles\")))\n",
    "g.add((cbr_xai_uri, HI.describedIn, paper_uri))\n",
    "g.add((cbr_xai_uri, HI.uses, landmark_cases_uri))\n",
    "g.add((cbr_xai_uri, HI.uses, precedential_constraint_uri))\n",
    "\n",
    "# 5. Dimension Ordering\n",
    "dimension_ordering_uri = HI[\"DimensionOrdering\"]\n",
    "g.add((dimension_ordering_uri, RDF.type, HI.AI_Concept))\n",
    "g.add((dimension_ordering_uri, HI.hasName, Literal(\"Dimension Ordering\")))\n",
    "g.add((dimension_ordering_uri, HI.hasDescription, Literal(\"A method to determine the orders for dimensions in case-based reasoning by using statistical trends like logistic regression coefficients\")))\n",
    "g.add((dimension_ordering_uri, HI.describedIn, paper_uri))\n",
    "g.add((dimension_ordering_uri, HI.partOf, precedential_constraint_uri))\n",
    "\n",
    "# Add tasks from the paper\n",
    "interpretability_task_uri = HI[\"AIInterpretabilityTask\"]\n",
    "g.add((interpretability_task_uri, RDF.type, HI.Task))\n",
    "g.add((interpretability_task_uri, HI.hasName, Literal(\"AI Interpretability\")))\n",
    "g.add((interpretability_task_uri, HI.hasDescription, Literal(\"The task of elucidating the decision making process of machine learning systems\")))\n",
    "g.add((interpretability_task_uri, HI.partOf, scenario_uri))\n",
    "g.add((interpretability_task_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "case_analysis_task_uri = HI[\"CaseAnalysisTask\"]\n",
    "g.add((case_analysis_task_uri, RDF.type, HI.Task))\n",
    "g.add((case_analysis_task_uri, HI.hasName, Literal(\"Case Analysis\")))\n",
    "g.add((case_analysis_task_uri, HI.hasDescription, Literal(\"The task of analyzing case data to identify landmark cases and determine consistency with precedence\")))\n",
    "g.add((case_analysis_task_uri, HI.partOf, scenario_uri))\n",
    "g.add((case_analysis_task_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "# Add human and AI agents\n",
    "researcher_uri = HI[\"CaseResearcher\"]\n",
    "g.add((researcher_uri, RDF.type, HI.Human_Agent))\n",
    "g.add((researcher_uri, HI.hasName, Literal(\"Case Researcher\")))\n",
    "g.add((researcher_uri, HI.hasDescription, Literal(\"Human researcher analyzing machine learning training data as legal cases through the lens of precedential constraint\")))\n",
    "g.add((researcher_uri, HI.describedIn, paper_uri))\n",
    "g.add((researcher_uri, HI.performsTask, case_analysis_task_uri))\n",
    "\n",
    "ai_system_uri = HI[\"CaseBasedReasoningSystem\"]\n",
    "g.add((ai_system_uri, RDF.type, HI.AI_Agent))\n",
    "g.add((ai_system_uri, HI.hasName, Literal(\"Case-Based Reasoning System\")))\n",
    "g.add((ai_system_uri, HI.hasDescription, Literal(\"AI system that provides explanations by analogy with training examples using case-based reasoning principles\")))\n",
    "g.add((ai_system_uri, HI.describedIn, paper_uri))\n",
    "g.add((ai_system_uri, HI.performsTask, interpretability_task_uri))\n",
    "g.add((ai_system_uri, HI.uses, precedential_constraint_uri))\n",
    "g.add((ai_system_uri, HI.uses, landmark_cases_uri))\n",
    "\n",
    "# Connect concepts to related concepts in other papers\n",
    "g.add((cbr_xai_uri, HI.relatedTo, HI.Trust))  # Relating to Trust concept\n",
    "g.add((cbr_xai_uri, HI.relatedTo, HI.UserControl))  # Relating to User Control concept\n",
    "\n",
    "# Add evaluation concepts\n",
    "consistency_eval_uri = HI[\"ConsistencyEvaluation\"] \n",
    "g.add((consistency_eval_uri, RDF.type, HI.Evaluation))\n",
    "g.add((consistency_eval_uri, HI.hasName, Literal(\"Consistency Evaluation\")))\n",
    "g.add((consistency_eval_uri, HI.hasDescription, Literal(\"Evaluation of the degree to which training data obeys the precedent set by other examples\")))\n",
    "g.add((consistency_eval_uri, HI.appliesTo, case_analysis_task_uri))\n",
    "g.add((consistency_eval_uri, HI.describedIn, paper_uri))\n",
    "\n",
    "compas_score_uri = HI[\"COMPASConsistencyScore\"]\n",
    "g.add((compas_score_uri, RDF.type, HI.Score))\n",
    "g.add((compas_score_uri, HI.hasName, Literal(\"COMPAS Consistency Score\")))\n",
    "g.add((compas_score_uri, HI.hasValue, Literal(0.08, datatype=XSD.float)))  # 8% consistent from the paper\n",
    "g.add((consistency_eval_uri, HI.hasResult, compas_score_uri))\n",
    "g.add((researcher_uri, HI.evaluatedWith, consistency_eval_uri))\n",
    "g.add((researcher_uri, HI.achievesScore, compas_score_uri))\n",
    "\n",
    "# Save the updated ontology\n",
    "g.serialize(destination=\"new_hi_ontology.ttl\", format=\"turtle\")\n",
    "print(\"Successfully added Landmarks in Case-Based Reasoning concepts to the ontology with proper relationships\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evoman",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
